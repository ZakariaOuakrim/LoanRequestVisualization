[2024-11-04T08:26:41.128+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-11-04T08:26:41.392+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Loan_Request_Report.Extract scheduled__2024-10-01T00:00:00+00:00 [queued]>
[2024-11-04T08:26:41.482+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Loan_Request_Report.Extract scheduled__2024-10-01T00:00:00+00:00 [queued]>
[2024-11-04T08:26:41.485+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-11-04T08:26:41.603+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): Extract> on 2024-10-01 00:00:00+00:00
[2024-11-04T08:26:41.652+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:62: DeprecationWarning: This process (pid=153) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-11-04T08:26:41.659+0000] {standard_task_runner.py:64} INFO - Started process 162 to run task
[2024-11-04T08:26:41.688+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'Loan_Request_Report', 'Extract', 'scheduled__2024-10-01T00:00:00+00:00', '--job-id', '11', '--raw', '--subdir', 'DAGS_FOLDER/dagLoanRequest.py', '--cfg-path', '/tmp/tmp4uwjrlye']
[2024-11-04T08:26:41.693+0000] {standard_task_runner.py:91} INFO - Job 11: Subtask Extract
[2024-11-04T08:26:42.110+0000] {task_command.py:426} INFO - Running <TaskInstance: Loan_Request_Report.Extract scheduled__2024-10-01T00:00:00+00:00 [running]> on host f4ed2a87aeca
[2024-11-04T08:26:42.831+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Loan_Request_Report' AIRFLOW_CTX_TASK_ID='Extract' AIRFLOW_CTX_EXECUTION_DATE='2024-10-01T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-10-01T00:00:00+00:00'
[2024-11-04T08:26:42.850+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-11-04T08:26:42.857+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-11-04T08:26:42.858+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 401, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/dagLoanRequest.py", line 31, in extract_task
    merged_df, original_df = extract_data_from_hive(kwargs['required_date'])
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etlProcess.py", line 84, in extract_data_from_hive
    conn = hive.Connection(host="hive-server", port=10000, database='m2t')
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyhive/hive.py", line 242, in __init__
    import thrift_sasl
ModuleNotFoundError: No module named 'thrift_sasl'
[2024-11-04T08:26:42.914+0000] {taskinstance.py:1206} INFO - Marking task as FAILED. dag_id=Loan_Request_Report, task_id=Extract, run_id=scheduled__2024-10-01T00:00:00+00:00, execution_date=20241001T000000, start_date=20241104T082641, end_date=20241104T082642
[2024-11-04T08:26:42.972+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 11 for task Extract (No module named 'thrift_sasl'; 162)
[2024-11-04T08:26:43.058+0000] {local_task_job_runner.py:243} INFO - Task exited with return code 1
[2024-11-04T08:26:43.271+0000] {taskinstance.py:3503} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-11-04T08:26:43.288+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-11-04T08:38:31.486+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-11-04T08:38:31.556+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Loan_Request_Report.Extract scheduled__2024-10-01T00:00:00+00:00 [queued]>
[2024-11-04T08:38:31.576+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Loan_Request_Report.Extract scheduled__2024-10-01T00:00:00+00:00 [queued]>
[2024-11-04T08:38:31.577+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-11-04T08:38:31.614+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): Extract> on 2024-10-01 00:00:00+00:00
[2024-11-04T08:38:31.632+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:62: DeprecationWarning: This process (pid=63) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-11-04T08:38:31.636+0000] {standard_task_runner.py:64} INFO - Started process 66 to run task
[2024-11-04T08:38:31.636+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'Loan_Request_Report', 'Extract', 'scheduled__2024-10-01T00:00:00+00:00', '--job-id', '16', '--raw', '--subdir', 'DAGS_FOLDER/dagLoanRequest.py', '--cfg-path', '/tmp/tmp0qbr7plf']
[2024-11-04T08:38:31.638+0000] {standard_task_runner.py:91} INFO - Job 16: Subtask Extract
[2024-11-04T08:38:31.807+0000] {task_command.py:426} INFO - Running <TaskInstance: Loan_Request_Report.Extract scheduled__2024-10-01T00:00:00+00:00 [running]> on host f4ed2a87aeca
[2024-11-04T08:38:32.345+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Loan_Request_Report' AIRFLOW_CTX_TASK_ID='Extract' AIRFLOW_CTX_EXECUTION_DATE='2024-10-01T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-10-01T00:00:00+00:00'
[2024-11-04T08:38:32.346+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-11-04T08:38:36.441+0000] {TSocket.py:133} ERROR - failed to resolve sockaddr for hive-server:10000
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/thrift/transport/TSocket.py", line 130, in open
    addrs = self._resolveAddr()
            ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/thrift/transport/TSocket.py", line 37, in _resolveAddr
    return socket.getaddrinfo(self.host,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/socket.py", line 964, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
socket.gaierror: [Errno -3] Temporary failure in name resolution
[2024-11-04T08:38:36.449+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-11-04T08:38:36.449+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/thrift/transport/TSocket.py", line 130, in open
    addrs = self._resolveAddr()
            ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/thrift/transport/TSocket.py", line 37, in _resolveAddr
    return socket.getaddrinfo(self.host,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/socket.py", line 964, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
socket.gaierror: [Errno -3] Temporary failure in name resolution

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 401, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/dagLoanRequest.py", line 31, in extract_task
    merged_df, original_df = extract_data_from_hive(kwargs['required_date'])
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etlProcess.py", line 84, in extract_data_from_hive
    conn = hive.Connection(host="hive-server", port=10000, database='m2t')
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyhive/hive.py", line 269, in __init__
    self._transport.open()
  File "/home/airflow/.local/lib/python3.12/site-packages/thrift_sasl/__init__.py", line 74, in open
    self._trans.open()
  File "/home/airflow/.local/lib/python3.12/site-packages/thrift/transport/TSocket.py", line 134, in open
    raise TTransportException(type=TTransportException.NOT_OPEN, message=msg, inner=gai)
thrift.transport.TTransport.TTransportException: failed to resolve sockaddr for hive-server:10000
[2024-11-04T08:38:36.494+0000] {taskinstance.py:1206} INFO - Marking task as FAILED. dag_id=Loan_Request_Report, task_id=Extract, run_id=scheduled__2024-10-01T00:00:00+00:00, execution_date=20241001T000000, start_date=20241104T083831, end_date=20241104T083836
[2024-11-04T08:38:36.533+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 16 for task Extract (failed to resolve sockaddr for hive-server:10000; 66)
[2024-11-04T08:38:36.570+0000] {local_task_job_runner.py:243} INFO - Task exited with return code 1
[2024-11-04T08:38:36.632+0000] {taskinstance.py:3503} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-11-04T08:38:36.644+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-11-04T22:00:16.234+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-11-04T22:00:16.354+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Loan_Request_Report.Extract scheduled__2024-10-01T00:00:00+00:00 [queued]>
[2024-11-04T22:00:16.380+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Loan_Request_Report.Extract scheduled__2024-10-01T00:00:00+00:00 [queued]>
[2024-11-04T22:00:16.381+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-11-04T22:00:16.424+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): Extract> on 2024-10-01 00:00:00+00:00
[2024-11-04T22:00:16.450+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:62: DeprecationWarning: This process (pid=122) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-11-04T22:00:16.454+0000] {standard_task_runner.py:64} INFO - Started process 124 to run task
[2024-11-04T22:00:16.456+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'Loan_Request_Report', 'Extract', 'scheduled__2024-10-01T00:00:00+00:00', '--job-id', '42', '--raw', '--subdir', 'DAGS_FOLDER/dagLoanRequest.py', '--cfg-path', '/tmp/tmp2sh0btub']
[2024-11-04T22:00:16.460+0000] {standard_task_runner.py:91} INFO - Job 42: Subtask Extract
[2024-11-04T22:00:16.600+0000] {task_command.py:426} INFO - Running <TaskInstance: Loan_Request_Report.Extract scheduled__2024-10-01T00:00:00+00:00 [running]> on host f4ed2a87aeca
[2024-11-04T22:00:16.866+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Loan_Request_Report' AIRFLOW_CTX_TASK_ID='Extract' AIRFLOW_CTX_EXECUTION_DATE='2024-10-01T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-10-01T00:00:00+00:00'
[2024-11-04T22:00:16.869+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-11-04T22:00:23.969+0000] {hive.py:475} INFO - USE `m2t`
[2024-11-04T22:00:48.960+0000] {warnings.py:112} WARNING - /opt/***/dags/etlProcess.py:136: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.
  df = pd.read_sql(query1, conn)

[2024-11-04T22:00:48.965+0000] {hive.py:475} INFO - 
        SELECT
            cl.id as id1,
            lr.id as id2,
            cl.phone_number AS N_GSM,
            cl.first_name  AS NOM,
            cl.last_name AS PRENOM,
            cl.age as age,
            cl.city_label as city,
            cl.gender as gender,
            lr.code_ls AS CODE_DOSSIER,
            lr.requested_amount AS MONTANT_DEMANDE,
            lr.awarded_amount AS MONTANT_ACCORDE,
            lr.created_date AS DATE_DEMANDE_CREDIT,
            SPLIT(lr.created_date, ' ')[1] AS HEURE_DEMANDE_CREDIT,
            lr.status AS STATUT_DOSSIER,
            lr.rejection_reason as rejection_reason,
            lr.requested_deadlines as NOMBRE_ECHEANCE,
            deadlines.deadline1 AS DATE_ECHEANCE1,
            deadlines.deadline2 AS DATE_ECHEANCE2,
            deadlines.deadline3 AS DATE_ECHEANCE3,
            deadlines.deadline4 AS DATE_ECHEANCE4,
            lr.fees AS FREE_DE_SERVICE,
            lr.rate AS TAUX_D_INTERET,
            CASE
                WHEN lr.code_es = '123456' THEN '012006'
                ELSE lr.code_es
            END AS CODE_AGENCE
        FROM clients cl
        LEFT JOIN loan_request lr ON cl.id = lr.fk_client
        LEFT JOIN (
            SELECT 
                fk_loan_request AS loan_request_id, 
                MAX(CASE WHEN deadline_row = 1 THEN deadline END) AS deadline1,
                MAX(CASE WHEN deadline_row = 2 THEN deadline END) AS deadline2,
                MAX(CASE WHEN deadline_row = 3 THEN deadline END) AS deadline3,
                MAX(CASE WHEN deadline_row = 4 THEN deadline END) AS deadline4
            FROM (
                SELECT 
                    fk_loan_request, 
                    deadline, 
                    ROW_NUMBER() OVER (PARTITION BY fk_loan_request ORDER BY deadline) AS deadline_row
                FROM payment_deadline
            ) deadline_subquery
            GROUP BY fk_loan_request
        ) AS deadlines ON lr.id = deadlines.loan_request_id
        WHERE lr.produit = 'TAYSSIR' AND date(lr.created_date) >= '2024-10-05'
        ORDER BY DATE_DEMANDE_CREDIT DESC
    
[2024-11-07T19:39:06.476+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-11-07T19:39:06.948+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Loan_Request_Report.Extract scheduled__2024-10-01T00:00:00+00:00 [queued]>
[2024-11-07T19:39:07.021+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Loan_Request_Report.Extract scheduled__2024-10-01T00:00:00+00:00 [queued]>
[2024-11-07T19:39:07.022+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-11-07T19:39:07.104+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): Extract> on 2024-10-01 00:00:00+00:00
[2024-11-07T19:39:07.260+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:62: DeprecationWarning: This process (pid=363) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-11-07T19:39:07.262+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'Loan_Request_Report', 'Extract', 'scheduled__2024-10-01T00:00:00+00:00', '--job-id', '184', '--raw', '--subdir', 'DAGS_FOLDER/dagLoanRequest.py', '--cfg-path', '/tmp/tmpv04ozr6y']
[2024-11-07T19:39:07.278+0000] {standard_task_runner.py:91} INFO - Job 184: Subtask Extract
[2024-11-07T19:39:07.323+0000] {standard_task_runner.py:64} INFO - Started process 373 to run task
[2024-11-07T19:39:08.670+0000] {task_command.py:426} INFO - Running <TaskInstance: Loan_Request_Report.Extract scheduled__2024-10-01T00:00:00+00:00 [running]> on host 2bac939b7bc7
[2024-11-07T19:39:10.431+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Loan_Request_Report' AIRFLOW_CTX_TASK_ID='Extract' AIRFLOW_CTX_EXECUTION_DATE='2024-10-01T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-10-01T00:00:00+00:00'
[2024-11-07T19:39:10.466+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-11-07T19:39:10.477+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-11-07T19:39:10.478+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 401, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/dagLoanRequest.py", line 31, in extract_task
    merged_df, original_df = extract_data_from_hive(kwargs['required_date'])
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etlProcess.py", line 86, in extract_data_from_hive
    conn = hive.Connection(host="hive-server", port=10000, database='m2t')
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyhive/hive.py", line 242, in __init__
    import thrift_sasl
ModuleNotFoundError: No module named 'thrift_sasl'
[2024-11-07T19:39:10.573+0000] {taskinstance.py:1206} INFO - Marking task as FAILED. dag_id=Loan_Request_Report, task_id=Extract, run_id=scheduled__2024-10-01T00:00:00+00:00, execution_date=20241001T000000, start_date=20241107T193906, end_date=20241107T193910
[2024-11-07T19:39:10.745+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 184 for task Extract (No module named 'thrift_sasl'; 373)
[2024-11-07T19:39:10.833+0000] {local_task_job_runner.py:243} INFO - Task exited with return code 1
[2024-11-07T19:39:11.139+0000] {taskinstance.py:3503} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-11-07T19:39:11.189+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-11-11T13:12:20.784+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-11-11T13:12:20.865+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Loan_Request_Report.Extract scheduled__2024-10-01T00:00:00+00:00 [queued]>
[2024-11-11T13:12:20.885+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Loan_Request_Report.Extract scheduled__2024-10-01T00:00:00+00:00 [queued]>
[2024-11-11T13:12:20.886+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-11-11T13:12:20.908+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): Extract> on 2024-10-01 00:00:00+00:00
[2024-11-11T13:12:20.929+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:62: DeprecationWarning: This process (pid=732) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-11-11T13:12:20.934+0000] {standard_task_runner.py:64} INFO - Started process 734 to run task
[2024-11-11T13:12:20.935+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'Loan_Request_Report', 'Extract', 'scheduled__2024-10-01T00:00:00+00:00', '--job-id', '248', '--raw', '--subdir', 'DAGS_FOLDER/dagLoanRequest.py', '--cfg-path', '/tmp/tmprbxewkbu']
[2024-11-11T13:12:20.942+0000] {standard_task_runner.py:91} INFO - Job 248: Subtask Extract
[2024-11-11T13:12:21.073+0000] {task_command.py:426} INFO - Running <TaskInstance: Loan_Request_Report.Extract scheduled__2024-10-01T00:00:00+00:00 [running]> on host 2bac939b7bc7
[2024-11-11T13:12:21.273+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Loan_Request_Report' AIRFLOW_CTX_TASK_ID='Extract' AIRFLOW_CTX_EXECUTION_DATE='2024-10-01T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-10-01T00:00:00+00:00'
[2024-11-11T13:12:21.277+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-11-11T13:12:21.721+0000] {hive.py:475} INFO - USE `m2t`
[2024-11-11T13:12:22.305+0000] {warnings.py:112} WARNING - /opt/***/dags/etlProcess.py:150: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.
  df = pd.read_sql(query1, conn)

[2024-11-11T13:12:22.306+0000] {hive.py:475} INFO - 
        SELECT
            cl.id as id1,
            lr.id as id2,
            cl.phone_number AS N_GSM,
            cl.first_name  AS NOM,
            cl.last_name AS PRENOM,
            cl.age as age,
            cl.city_label as city,
            cl.gender as gender,
            lr.code_ls AS CODE_DOSSIER,
            lr.requested_amount AS MONTANT_DEMANDE,
            lr.awarded_amount AS MONTANT_ACCORDE,
            lr.created_date AS DATE_DEMANDE_CREDIT,
            SPLIT(lr.created_date, ' ')[1] AS HEURE_DEMANDE_CREDIT,
            lr.status AS STATUT_DOSSIER,
            lr.rejection_reason as rejection_reason,
            lr.requested_deadlines as NOMBRE_ECHEANCE,
            deadlines.deadline1 AS DATE_ECHEANCE1,
            deadlines.deadline2 AS DATE_ECHEANCE2,
            deadlines.deadline3 AS DATE_ECHEANCE3,
            deadlines.deadline4 AS DATE_ECHEANCE4,
            lr.fees AS FREE_DE_SERVICE,
            lr.rate AS TAUX_D_INTERET,
            CASE
                WHEN lr.code_es = '123456' THEN '012006'
                ELSE lr.code_es
            END AS CODE_AGENCE
        FROM clients cl
        LEFT JOIN loan_request lr ON cl.id = lr.fk_client
        LEFT JOIN (
            SELECT 
                fk_loan_request AS loan_request_id, 
                MAX(CASE WHEN deadline_row = 1 THEN deadline END) AS deadline1,
                MAX(CASE WHEN deadline_row = 2 THEN deadline END) AS deadline2,
                MAX(CASE WHEN deadline_row = 3 THEN deadline END) AS deadline3,
                MAX(CASE WHEN deadline_row = 4 THEN deadline END) AS deadline4
            FROM (
                SELECT 
                    fk_loan_request, 
                    deadline, 
                    ROW_NUMBER() OVER (PARTITION BY fk_loan_request ORDER BY deadline) AS deadline_row
                FROM payment_deadline
            ) deadline_subquery
            GROUP BY fk_loan_request
        ) AS deadlines ON lr.id = deadlines.loan_request_id
        WHERE lr.produit = 'TAYSSIR' AND date(lr.created_date) >= '2024-06-13'
        ORDER BY DATE_DEMANDE_CREDIT DESC
    
[2024-11-12T14:06:23.569+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-11-12T14:06:23.962+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Loan_Request_Report.Extract scheduled__2024-10-01T00:00:00+00:00 [queued]>
[2024-11-12T14:06:24.031+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Loan_Request_Report.Extract scheduled__2024-10-01T00:00:00+00:00 [queued]>
[2024-11-12T14:06:24.032+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-11-12T14:06:24.141+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): Extract> on 2024-10-01 00:00:00+00:00
[2024-11-12T14:06:24.170+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:62: DeprecationWarning: This process (pid=92) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-11-12T14:06:24.174+0000] {standard_task_runner.py:64} INFO - Started process 94 to run task
[2024-11-12T14:06:24.197+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'Loan_Request_Report', 'Extract', 'scheduled__2024-10-01T00:00:00+00:00', '--job-id', '292', '--raw', '--subdir', 'DAGS_FOLDER/dagLoanRequest.py', '--cfg-path', '/tmp/tmpg4die69s']
[2024-11-12T14:06:24.200+0000] {standard_task_runner.py:91} INFO - Job 292: Subtask Extract
[2024-11-12T14:06:25.281+0000] {task_command.py:426} INFO - Running <TaskInstance: Loan_Request_Report.Extract scheduled__2024-10-01T00:00:00+00:00 [running]> on host 2bac939b7bc7
[2024-11-12T14:06:25.975+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Loan_Request_Report' AIRFLOW_CTX_TASK_ID='Extract' AIRFLOW_CTX_EXECUTION_DATE='2024-10-01T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-10-01T00:00:00+00:00'
[2024-11-12T14:06:25.985+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-11-12T14:06:37.466+0000] {hive.py:475} INFO - USE `m2t`
[2024-11-12T14:07:10.536+0000] {warnings.py:112} WARNING - /opt/***/dags/etlProcess.py:150: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.
  df = pd.read_sql(query1, conn)

[2024-11-12T14:07:10.538+0000] {hive.py:475} INFO - 
        SELECT
            cl.id as id1,
            lr.id as id2,
            cl.phone_number AS N_GSM,
            cl.first_name  AS NOM,
            cl.last_name AS PRENOM,
            cl.age as age,
            cl.city_label as city,
            cl.gender as gender,
            lr.code_ls AS CODE_DOSSIER,
            lr.requested_amount AS MONTANT_DEMANDE,
            lr.awarded_amount AS MONTANT_ACCORDE,
            lr.created_date AS DATE_DEMANDE_CREDIT,
            SPLIT(lr.created_date, ' ')[1] AS HEURE_DEMANDE_CREDIT,
            lr.status AS STATUT_DOSSIER,
            lr.rejection_reason as rejection_reason,
            lr.requested_deadlines as NOMBRE_ECHEANCE,
            deadlines.deadline1 AS DATE_ECHEANCE1,
            deadlines.deadline2 AS DATE_ECHEANCE2,
            deadlines.deadline3 AS DATE_ECHEANCE3,
            deadlines.deadline4 AS DATE_ECHEANCE4,
            lr.fees AS FREE_DE_SERVICE,
            lr.rate AS TAUX_D_INTERET,
            CASE
                WHEN lr.code_es = '123456' THEN '012006'
                ELSE lr.code_es
            END AS CODE_AGENCE
        FROM clients cl
        LEFT JOIN loan_request lr ON cl.id = lr.fk_client
        LEFT JOIN (
            SELECT 
                fk_loan_request AS loan_request_id, 
                MAX(CASE WHEN deadline_row = 1 THEN deadline END) AS deadline1,
                MAX(CASE WHEN deadline_row = 2 THEN deadline END) AS deadline2,
                MAX(CASE WHEN deadline_row = 3 THEN deadline END) AS deadline3,
                MAX(CASE WHEN deadline_row = 4 THEN deadline END) AS deadline4
            FROM (
                SELECT 
                    fk_loan_request, 
                    deadline, 
                    ROW_NUMBER() OVER (PARTITION BY fk_loan_request ORDER BY deadline) AS deadline_row
                FROM payment_deadline
            ) deadline_subquery
            GROUP BY fk_loan_request
        ) AS deadlines ON lr.id = deadlines.loan_request_id
        WHERE lr.produit = 'TAYSSIR' AND date(lr.created_date) >= '2024-06-13'
        ORDER BY DATE_DEMANDE_CREDIT DESC
    
[2024-11-12T14:07:17.328+0000] {local_task_job_runner.py:313} WARNING - State of this instance has been externally set to restarting. Terminating instance.
[2024-11-12T14:07:17.362+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-11-12T14:07:17.404+0000] {process_utils.py:132} INFO - Sending 15 to group 94. PIDs of all processes in the group: [94]
[2024-11-12T14:07:17.406+0000] {process_utils.py:87} INFO - Sending the signal 15 to group 94
[2024-11-12T14:07:17.413+0000] {taskinstance.py:2611} ERROR - Received SIGTERM. Terminating subprocesses.
[2024-11-12T14:07:17.422+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-11-12T14:07:17.670+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 401, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/dagLoanRequest.py", line 36, in extract_task
    merged_df, original_df = extract_data_from_hive(kwargs['required_date'])
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etlProcess.py", line 150, in extract_data_from_hive
    df = pd.read_sql(query1, conn)
       ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 654, in read_sql
    return pandas_sql.read_query(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 2326, in read_query
    cursor = self.execute(sql, params)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 2262, in execute
    cur.execute(sql, *args)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyhive/hive.py", line 480, in execute
    response = self._connection.client.ExecuteStatement(req)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/TCLIService/TCLIService.py", line 280, in ExecuteStatement
    return self.recv_ExecuteStatement()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/TCLIService/TCLIService.py", line 292, in recv_ExecuteStatement
    (fname, mtype, rseqid) = iprot.readMessageBegin()
                             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/thrift/protocol/TBinaryProtocol.py", line 135, in readMessageBegin
    sz = self.readI32()
         ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/thrift/protocol/TBinaryProtocol.py", line 218, in readI32
    buff = self.trans.readAll(4)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/thrift/transport/TTransport.py", line 62, in readAll
    chunk = self.read(sz - have)
            ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/thrift_sasl/__init__.py", line 173, in read
    self._read_frame()
  File "/home/airflow/.local/lib/python3.12/site-packages/thrift_sasl/__init__.py", line 177, in _read_frame
    header = self._trans_read_all(4)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/thrift_sasl/__init__.py", line 210, in _trans_read_all
    return read_all(sz)
           ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/thrift/transport/TTransport.py", line 62, in readAll
    chunk = self.read(sz - have)
            ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/thrift/transport/TSocket.py", line 157, in read
    buff = self.handle.recv(sz)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 2613, in signal_handler
    raise AirflowTaskTerminated("Task received SIGTERM signal")
airflow.exceptions.AirflowTaskTerminated: Task received SIGTERM signal
[2024-11-12T14:07:17.894+0000] {taskinstance.py:1206} INFO - Marking task as UP_FOR_RETRY. dag_id=Loan_Request_Report, task_id=Extract, run_id=scheduled__2024-10-01T00:00:00+00:00, execution_date=20241001T000000, start_date=20241112T140623, end_date=20241112T140717
[2024-11-12T14:07:18.152+0000] {process_utils.py:80} INFO - Process psutil.Process(pid=94, status='terminated', exitcode=2, started='14:06:24') (94) terminated with exit code 2
[2024-11-28T23:13:05.046+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-11-28T23:13:05.153+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Loan_Request_Report.Extract scheduled__2024-10-01T00:00:00+00:00 [queued]>
[2024-11-28T23:13:05.178+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Loan_Request_Report.Extract scheduled__2024-10-01T00:00:00+00:00 [queued]>
[2024-11-28T23:13:05.179+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-11-28T23:13:05.254+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): Extract> on 2024-10-01 00:00:00+00:00
[2024-11-28T23:13:05.487+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:62: DeprecationWarning: This process (pid=65) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-11-28T23:13:05.528+0000] {standard_task_runner.py:64} INFO - Started process 67 to run task
[2024-11-28T23:13:05.538+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'Loan_Request_Report', 'Extract', 'scheduled__2024-10-01T00:00:00+00:00', '--job-id', '391', '--raw', '--subdir', 'DAGS_FOLDER/dagLoanRequest.py', '--cfg-path', '/tmp/tmpc06v4pz7']
[2024-11-28T23:13:05.546+0000] {standard_task_runner.py:91} INFO - Job 391: Subtask Extract
[2024-11-28T23:13:06.026+0000] {task_command.py:426} INFO - Running <TaskInstance: Loan_Request_Report.Extract scheduled__2024-10-01T00:00:00+00:00 [running]> on host 97460a9713a2
[2024-11-28T23:13:07.142+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Loan_Request_Report' AIRFLOW_CTX_TASK_ID='Extract' AIRFLOW_CTX_EXECUTION_DATE='2024-10-01T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-10-01T00:00:00+00:00'
[2024-11-28T23:13:07.154+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-11-28T23:13:11.253+0000] {TSocket.py:133} ERROR - failed to resolve sockaddr for hive-server:10000
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/thrift/transport/TSocket.py", line 130, in open
    addrs = self._resolveAddr()
            ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/thrift/transport/TSocket.py", line 37, in _resolveAddr
    return socket.getaddrinfo(self.host,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/socket.py", line 964, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
socket.gaierror: [Errno -3] Temporary failure in name resolution
[2024-11-28T23:13:11.332+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-11-28T23:13:11.398+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/thrift/transport/TSocket.py", line 130, in open
    addrs = self._resolveAddr()
            ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/thrift/transport/TSocket.py", line 37, in _resolveAddr
    return socket.getaddrinfo(self.host,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/socket.py", line 964, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
socket.gaierror: [Errno -3] Temporary failure in name resolution

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 401, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/dagLoanRequest.py", line 36, in extract_task
    merged_df, original_df = extract_data_from_hive(kwargs['required_date'])
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etlProcess.py", line 113, in extract_data_from_hive
    conn = hive.Connection(host="hive-server", port=10000, database='m2t')
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyhive/hive.py", line 269, in __init__
    self._transport.open()
  File "/home/airflow/.local/lib/python3.12/site-packages/thrift_sasl/__init__.py", line 74, in open
    self._trans.open()
  File "/home/airflow/.local/lib/python3.12/site-packages/thrift/transport/TSocket.py", line 134, in open
    raise TTransportException(type=TTransportException.NOT_OPEN, message=msg, inner=gai)
thrift.transport.TTransport.TTransportException: failed to resolve sockaddr for hive-server:10000
[2024-11-28T23:13:11.530+0000] {taskinstance.py:1206} INFO - Marking task as FAILED. dag_id=Loan_Request_Report, task_id=Extract, run_id=scheduled__2024-10-01T00:00:00+00:00, execution_date=20241001T000000, start_date=20241128T231305, end_date=20241128T231311
[2024-11-28T23:13:11.687+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 391 for task Extract (failed to resolve sockaddr for hive-server:10000; 67)
[2024-11-28T23:13:11.745+0000] {local_task_job_runner.py:243} INFO - Task exited with return code 1
[2024-11-28T23:13:11.874+0000] {taskinstance.py:3503} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-11-28T23:13:11.889+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-11-29T00:42:55.957+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-11-29T00:42:56.067+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Loan_Request_Report.Extract scheduled__2024-10-01T00:00:00+00:00 [queued]>
[2024-11-29T00:42:56.095+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Loan_Request_Report.Extract scheduled__2024-10-01T00:00:00+00:00 [queued]>
[2024-11-29T00:42:56.096+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-11-29T00:42:56.153+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): Extract> on 2024-10-01 00:00:00+00:00
[2024-11-29T00:42:56.168+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:62: DeprecationWarning: This process (pid=106) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-11-29T00:42:56.172+0000] {standard_task_runner.py:64} INFO - Started process 108 to run task
[2024-11-29T00:42:56.171+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'Loan_Request_Report', 'Extract', 'scheduled__2024-10-01T00:00:00+00:00', '--job-id', '408', '--raw', '--subdir', 'DAGS_FOLDER/dagLoanRequest.py', '--cfg-path', '/tmp/tmpk57wqdzr']
[2024-11-29T00:42:56.173+0000] {standard_task_runner.py:91} INFO - Job 408: Subtask Extract
[2024-11-29T00:42:56.265+0000] {task_command.py:426} INFO - Running <TaskInstance: Loan_Request_Report.Extract scheduled__2024-10-01T00:00:00+00:00 [running]> on host 97460a9713a2
[2024-11-29T00:42:56.414+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Loan_Request_Report' AIRFLOW_CTX_TASK_ID='Extract' AIRFLOW_CTX_EXECUTION_DATE='2024-10-01T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-10-01T00:00:00+00:00'
[2024-11-29T00:42:56.416+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-11-29T00:43:06.557+0000] {hive.py:475} INFO - USE `m2t`
[2024-11-29T00:44:24.982+0000] {warnings.py:112} WARNING - /opt/***/dags/etlProcess.py:165: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.
  df = pd.read_sql(query1, conn)

[2024-11-29T00:44:24.988+0000] {hive.py:475} INFO - 
        SELECT
            cl.id as id1,
            lr.id as id2,
            cl.phone_number AS N_GSM,
            cl.first_name  AS NOM,
            cl.last_name AS PRENOM,
            cl.age as age,
            cl.city_label as city,
            cl.gender as gender,
            lr.code_ls AS CODE_DOSSIER,
            lr.requested_amount AS MONTANT_DEMANDE,
            lr.awarded_amount AS MONTANT_ACCORDE,
            lr.created_date AS DATE_DEMANDE_CREDIT,
            SPLIT(lr.created_date, ' ')[1] AS HEURE_DEMANDE_CREDIT,
            lr.status AS STATUT_DOSSIER,
            lr.rejection_reason as rejection_reason,
            lr.requested_deadlines as NOMBRE_ECHEANCE,
            deadlines.deadline1 AS DATE_ECHEANCE1,
            deadlines.deadline2 AS DATE_ECHEANCE2,
            deadlines.deadline3 AS DATE_ECHEANCE3,
            deadlines.deadline4 AS DATE_ECHEANCE4,
            lr.fees AS FREE_DE_SERVICE,
            lr.rate AS TAUX_D_INTERET,
            CASE
                WHEN lr.code_es = '123456' THEN '012006'
                ELSE lr.code_es
            END AS CODE_AGENCE
        FROM clients cl
        LEFT JOIN loan_request lr ON cl.id = lr.fk_client
        LEFT JOIN (
            SELECT 
                fk_loan_request AS loan_request_id, 
                MAX(CASE WHEN deadline_row = 1 THEN deadline END) AS deadline1,
                MAX(CASE WHEN deadline_row = 2 THEN deadline END) AS deadline2,
                MAX(CASE WHEN deadline_row = 3 THEN deadline END) AS deadline3,
                MAX(CASE WHEN deadline_row = 4 THEN deadline END) AS deadline4
            FROM (
                SELECT 
                    fk_loan_request, 
                    deadline, 
                    ROW_NUMBER() OVER (PARTITION BY fk_loan_request ORDER BY deadline) AS deadline_row
                FROM payment_deadline
            ) deadline_subquery
            GROUP BY fk_loan_request
        ) AS deadlines ON lr.id = deadlines.loan_request_id
        WHERE lr.produit = 'TAYSSIR' AND date(lr.created_date) >= '2024-06-13'
        ORDER BY DATE_DEMANDE_CREDIT DESC
    
[2024-11-29T00:46:40.286+0000] {job.py:218} ERROR - Job heartbeat got an exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 256, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/jobs/job.py", line 213, in heartbeat
    heartbeat_callback(session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/jobs/local_task_job_runner.py", line 261, in heartbeat_callback
    self.task_instance.refresh_from_db()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 1821, in refresh_from_db
    _refresh_from_db(task_instance=self, session=session, lock_for_update=lock_for_update)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 510, in _refresh_from_db
    ti = TaskInstance.get_task_instance(
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 1807, in get_task_instance
    return query.one_or_none()
           ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/query.py", line 2850, in one_or_none
    return self._iter().one_or_none()
           ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/query.py", line 2916, in _iter
    result = self.session.execute(
             ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/future/engine.py", line 412, in connect
    return super(Engine, self).connect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 256, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2024-11-29T00:46:44.240+0000] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
